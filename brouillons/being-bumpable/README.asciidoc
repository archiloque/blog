= Fiche de lecture{nbsp}: "`Being bumpable: Consequences of resource saturation and near-saturation for cognitive demands on ICU practitioners`"
Julien Kirch
v0.1, 2023-05-15
:article_lang: fr

link:https://www.researchgate.net/publication/310477084_Being_bumpable_Consequences_of_resource_saturation_and_near-saturation_for_cognitive_demands_on_ICU_practitioners[Le texte en question] est une étude du travail des anesthésistes.

Il s'agit d'un travail complexe dans un environement et changeant.
Elle ressemble un peu à celle du développement logiciel et beaucoup à celle d'investigation lors d'incidents de production (d'ailleurs link:https://www.researchgate.net/profile/Richard-Cook-8[l'auteur a également écrit sur ce sujet]).

Pour progresser dans leur travail, les anesthésistes organisent des points d'échanges pour discuter ensembles des interventions qui se sont mal passées.
Deux choses semblent distinguer ce domaine par rapport à d'autres domaines complexes comme la sureté aérienne ou la lutte contre les incendies sur lesquels j'avais déjà lu des choses :

- Les manières de faire évoluent de manière régulière en fonction des nouvelles études et produits disponibles,
- hors des situations standard, il n'y a pas forcément une seule manière d'approcher une interventions mais plusieurs, en fonction par exemple de la manière dont on évalue tel ou tel risque.

Ce qui fait qu'il y a des discussions où on les personnes pèsent le pour et le contre entre différentes habitudes sans qu'il y ait consensus.

== Le mauvais modèle mental

La biologie humaine est complexe, pour être en mesure de prendre des décisions les anesthésistes ont besoin de se baser sur un modèle mental simplifié de leur patient·e.

L'étude du dossier médical et les questions qui sont posées avant les opérations permettent de choisir quel modèle mental utiliser.

Le texte étudie en détail le problème de rester bloqué sur un certain modèle mental alors qu'il n'est plus adapté.
En effet la personne qui intervient face à une situation d'urgence doit à la fois choisir quoi faire parmi les options possible de son modèle mental en cours, tout en gardant le recul qui lui permettrait si nécessaire de remettre en cause son modèle mental.

== 


== Quelques citations

[quote]
____
In anesthesiology, as in other complex dynamic worlds, single factors rarely cause accidents.
Rather accidents develop or evolve through a conjunction of several small factors, each by itself insufficient to create an incident. One important role of the
anesthesiologist is to prevent these single factors from developing and combining to produce an accident.
The progression of an incident towards or away from a bad outcome rests, often literally, in the hands of
the practitioner. Skilled human actions can steer the evolving incident towards satisfactory outcomes.
Much of anesthesia training is directed towards developing precisely this kind of skill. When disasters do
occur, they often involve the conjuction of multiple factors which overwhelm, sometimes overtly and
sometimes subtely, the ability of the physician to cope with the disturbance. Because the anesthesiologist
is the final common pathway for incidents, he or she is often regarded as the source of error when
anesthesia accidents come to attention. As Rasmussen points out,

[quote]
_____
if a system performs less satisfactorily than it normally does
the cause will very likely be identified as human
error… Because of human complexity, it is very difficult to "`pass through`" a person in causal explanations
Ultimately, a thorough analysis will always end up with human error
(Rasmussen, 1986).
_____
____

[quote]
____
Note that this is ultimately a process of directing attention to different parts of the stimulus world
based on the pattern of cues and on previously activated knowledge. Focusing attention is critical to
practitioners' ability to function in multi-signal, interleaved task domains. There are so many possible
stimuli that paying attention to all of them is impossible as well as unproductive. Note, however, that it
is not simply the loudness or brightness of the stimulus that draws attention but rather these features
coupled with the experience of the practitioner at gleaning from many stimuli those which have
significance in the current context. As experience in these complex domains grows, so does the ability to
discriminate between the meaningful and meaningless stimuli. Thus the novice focuses seemingly at
random on each source of data, each bright thing, while experts' attention shifts only to significant
findings.
____

[quote]
____
For example, one senior anesthesiologist asked about the policy of an instution regarding the care for emergent C-sections
replied: "`Our policy is to do the right thing`".
____

[quote]
____
Many phenomena are similarly infrequent. For example, the incidence of unintubatable,
unmaskable patient is quite low, and the condition may be difficult to predict. Yet, expertise in
anesthesia, as in similar high consequence domains, consists in large part of being able to avoid these
situations and deal with them when they arise. That is to say, _expertise is largely concerned with infrequent or unusual situations_. It is not acceptable for the anesthesiologist to say, well, this is really infrequent and
so I couldn't handle the situation; the function of training and study is to prepare for these rare events.
Note, however, that the nature of experience generally is _contrary_ to training: it reinforces the typical, high
frequency situation. One may give two milligrams of midazolam repeatedly without complication and
learn (in the sense that the cognitive cycle prompts particular schemata to be activated) that doing so is
acceptable.
____

[quote]
____
One consequence of the cognitive cycle is that particular perceptual stimuli arouse specific but
varied items of knowledge. Some items require very particular stimuli in order to be activated; it is quite
possible for individuals to "`know`" something in one setting and not in another.
Knowledge important to a situation but not active is called "`inert knowledge`"
____

[quote]
____
Thus the demonstration that a practitioner has the knowledge in the sense that he or she can
answer questions, does not guarantee that the same knowledge will be activated under appropriate
circumstances.

Failure to activate relevant knowledge is a frequent occurrence in complex domains and
frequently plays a role in the cases comprising the corpus.
____

[quote]
____
Limiting cognitive workload can also be accomplished by reducing the variability of the world in
order to reduce the dimensions of the problem space. There are two main methods of reducing the
variety that confronts the anesthesiologist. The first is by actually simplifying the world itself. For
example, the practitioner may arrange syringes on the backstand in a certain way to reduce the effort
necessary to find them. Organization of the workspace in general is a means of reducing the variability in
the world. These strategies are particularly useful because the simplification usually requires effort at
low workload times (e.g. setting up before the case).

The other method of reducing the variability of the world is by simplifying the cognitive tasks
themselves, usually by employing defaults values (assumptions) or simplified models which are
cognitively easier to manipulate. For example, Patel, et al. (1989) have found that many practitioners
have in inaccurate model of congestive heart failure but this model may actually be quite useful because
it is simpler and more easily manipulated than a more accurate model. The value of a model of the world
depends mostly on what results one can derive from it. Successful practitioners must, by definition, have
fairly reliable models even if these models can be shown to be incorrect in some theoretical sense. The
potential for error lies in the non-standard case, in which the model or assumption is inadequate.

Note that the simplified versions of the cognitive tasks are not likely to be developed unless they
(a) reduce cognitive effort and (b) are usually correct. In a case reported to us one year before the corpus
data collection began, emergent reintubation for residual paralysis was complicated by a monitor which
appeared to be showing a flat end-tidal carbon dioxide waveform. The endotracheal tube was removed
and direct laryngoscopy repeated. In fact the monitor was set to display a different waveform in that
screen location. There was a faulty indication (flat line trace) that the endotracheal tube was in the
esophagus. Interestingly, the same person who had set the monitor up for that other waveform also read
the flat line as 'no end-tidal carbon dioxide'. To do this it was necessary to have used an assumption
about the state of the monitor (i.e. that the flat trace represented carbon dioxide) which was incorrect.
The monitor itself contributed to the misperception because its indication of which trace was being
displayed was not perceptually salient (it consisted of a small LED indicator well away from the video
screen and a screen label in small type in a noisy background).
These two forms of simplification most often appear together. In example just given, the
anesthesiologist always set the monitor to display end-tidal carbon dioxide during preoperative
equipment checkout. This ordering of the world constitutes a means of reducing the variability in the
environment. The assumption, that the screen trace was carbon dioxide, was thus made valid for the
period of induction and intubation. In the case, however, the intubation was undertaken at an unusual
time. Under the pressure of the emergent reintubation, the demand for cognitive efficiency was coupled
with the act of intubation and led to employment of the assumption that the trace was carbon dioxide.
Thus the standard procedure of reducing variability in the world supported the assumption of a default
value (that the trace configuration showed carbon dioxide) when, because of unusual circumstances, it
was actually incorrect.
The assumption of default value is normal and useful for practitioners under most circumstances.
Indeed, it is actually impossible to avoid deriving assumptions and using simplified models. All complex»
domains, including anesthesiology, are so semantically complex that it would be impossible for
practitioners to constantly check all components of their internal mental model against the actual state of the world.
____

[quote]
____
Naive critiques of domain practice often indict the assumptions of default values and the use of
simplified models. In retrospect all assumptions are susceptible to flaws which may contribute to poor
performance. What such criticisms fail to do, however, is acknowledge that high quality domain
performance is often dependent on these same assumptions. It would be impossible to test every
assumption about the state of the system at each instant. Even if it were theoretically possible to do so,
requiring such tests would cripple cognitive processing. Any practitioner confronted with such a "`rule`"
would necessarily learn the aspects of it relevant to the actual contexts seen and discard the remainder.
Practitioners learn by experience which ones are likely to be true and which are more vulnerable.
____

[quote]
____
In real situations, such as the case above, there may be many influences operating simultaneously
in a changing environment. The practitioner is charged with sorting out the influences and effects in real
time. He or she must keep track of what is working and what is not, whether the interventions are
successful, what is likely to happen next, etc. Anesthesiology, like similar domains, deals with volatile
and fast paced situations. It is critically important that practitioners build and maintain a coherent
"`situation awareness`" , which makes sense of the multiple factors at work
including faults, operator interventions and automatic system responses (e.g. the functioning of infusion
devices). Researchers examining expertise in situ have noted that practitioners themselves coin phrases to
describe this ability to maintain a coherent view of the changing situation: in commercial aviation it is
sometimes referred to as _flying ahead of the plane_, in carrier flightdeck operations it is called _having the bubble_ and von Clausewitz called it _coup d'œil_ on the battlefield. Situation assessment is
what allows practitioners to to determine where and when decisive action can be taken.

Being able to exercise effective control over a situation demands first that the practitioner track
the state of the system. This means not only determining the condition of the patient but also the external
and internal influences which are acting to produce that state. Practitioners need to keep a running tab of
the influences acting on the patient. To make this possible they may adopt control strategies which
minimize the overlap of different influences in order to eliminate the need to separate their contributions.

When situation assessment is lost, that is, when the practitioner is no longer tracking the
influences and effects with sufficient precision to permit meaningful interventions, the practitioner has
"`lost the bubble`". Losing the bubble can have grave consequences if the situation is precarious or
changing. Most practitioners in these domains can describe personal experiences which fit the definition
of loosing the bubble and, many times, these are cases which resulted in near disaster.
It is difficult to detect loss of situation awareness in the conference cases. A good part of the
anesthesiologist's training is oriented towards avoiding the loss of situation awareness and on reestablishing it when it is absent.
____

[quote]
____
Reviewing and altering plans under pressure is difficult and may even be impossible given the
demands for immediate action. But planning can be undertaken to various depths. Planning is not
simply the selection of a single approach to a problem but rather the construction of a collection of
approaches for a variety of different circumstances. The difference between simplistic planning ("`I will
do X for this case`") and extensive planning ("`I will do X for this case but will be prepared to do Y under
certain circumstances and Z under others`") can be crucial in event driven, high uncertainty domains like
anesthesiology.

This extensive planning is cognitively effortful and demands integration of large amounts of
material. The situations for which the alternative courses of action are required rarely occur (e.g. unable
to intubate, unable to mask) and so there is little reinforcement for extensive contingent planning.
____
