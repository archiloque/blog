= 14^th^ April 2019
Julien Kirch
v1.0, 2019-04-14
:article_lang: en

== link:https://queue.acm.org/detail.cfm?id=637960[The Deliberate Revolution]

[quote]
____
This article attempts to dive beneath the hype, examining how XML web services differ from existing architectures, and how they might help build customer solutions. Let's begin by describing features of XML web services, which:

* _Are not remote procedure calls._ Now to stir the pot a little: good web services are not modeled as remote procedure calls (RPCs). Section 7 of the SOAP 1.1 specification describes how to express a remote procedure call in the Body element of a SOAP message. This is a useful mechanism for tunneling RPCs between systems, but SOAP-RPC is a poor approach to designing an interoperable web service. RPC is primarily designed to support object invocation between tightly bound but topologically distributed systems. Yes, you can still achieve interoperability while using “RPC/Encoded” SOAP messages, but the focus on objects and method invocation is fundamentally contrary to the document-centric philosophy of web services. SOAP messages can be in two styles, "RPC" and "Document," and can use two serialization formats, "Encoded" and "Literal." In practice, SOAP-RPC uses "RPC/Encoded," while document-centric web services use "Document/Literal." By failing to focus on the service contract, you provide for brittle integration. Minor changes to a method signature automatically get propagated to the service, causing current clients to break. Great toolkits exist for doing tightly-bound RPC over SOAP from various vendors. If this is what you are looking for, find the one that works best for your platform. But if you are trying to design for interoperability, design your messages first and then write your methods to support them, not the other way around.

* _Is not CORBA._ Making the messages and the service contracts the design center of web services is the fundamental difference between the web services architecture and CORBA. There are strong analogies between elements of the two architectures, such as the respective roles of WSDL and IDL, but CORBA is fundamentally object-oriented. The messages CORBA passes are manipulated by instantiating an object. The document-style messages used in web services offer more flexibility for manipulation; for example, an interception service (more on this pattern later) might operate on one document header element, without having the logic to understand the rest of the document. As the technologies of web service rapidly evolve in the years ahead, standards bodies, including the W3C and IETF, will be instrumental in smoothing the rougher edges of the web service specifications. But these technologies are mature enough -- and widely adopted enough -- to be actionable today.
____

== link:https://blog.lawrencejones.dev/building-a-postgresql-load-tester/[Building a PostgreSQL load tester]

[quote]
____
When faced with a technical problem it’s often better to use an existing tool than jump into writing one yourself. Having benchmarked Postgres clusters before, I was already familiar with a tool called link:https://github.com/laurenz/pgreplay[pgreplay] that I thought could do the job.

My benchmarking strategy with pgreplay is pretty simple: first capture logs from your production cluster that contain all executed queries then feed this to pgreplay which will replay those queries against the new cluster. Post-processing logs from the new cluster will show how the machines performed under production load, helping determine if changes are going to degrade performance.

This process had worked well before but broke as soon as I applied it to this migration. Watching Postgres during a replay, there were spikes of activity followed by periods of quiet.

The new cluster was sufficiently different that several queries were now much slower than they had been in the original log capture. pgreplay will ensure queries execute in their original order- any queries that take longer to execute in the replay will block subsequent queries. The graph shows how several badly degraded queries caused pgreplay to stall, leading to the periods of inactivity.

Benchmarks can take several hours to execute and having the replay stall for problematic queries adds more time to an already slow process. The inactivity also impacts the realism of your tests- users don’t respond to a system under load by forming a queue and politely waiting for their first query to finish!
____

== link:https://queue.acm.org/detail.cfm?id=864078[A Conversation with Jim Gray]

[quote]
____
There is this really elegant theory about transactions, having to do with concurrency and recovery. A lot of people had implemented these ideas implicitly. I wrote a mathematical theory around it and explained it and did a fairly crisp implementation of the ideas. The Turing Award committee likes crisp results. The embarrassing thing is that I did it with a whole bunch of other people. But I wrote the papers, and my name was often first on the list of authors. So, I got the credit.

But to return to your question, the fundamental premise of transactions is that we needed exception handling in distributed computations. Transactions are the computer equivalent of contract law. If anything goes wrong, we’ll just blow away the whole computation. Absent some better model, that’s a real simple model that everybody can understand. There’s actually a mathematical theory lying underneath it.

In addition, there is a great deal of logic about keeping a log of changes so that you can undo things, and keeping a list of updates, called locks, so that others do not see your uncommitted changes.The theory says: “If that’s what you want to do, this is what you have to do to get it.”

The algorithms are simple enough so most implementers can understand them, and they are complicated enough so most people who can’t understand them will want somebody else to figure it out for them.
____

== link:https://summitroute.com/downloads/aws_security_maturity_roadmap-Summit_Route_2019.pdf[AWS Security Maturity Roadmap]

[quote]
____
Planning for Disaster Recovery involves a trade-off between how quickly you need to recover and how much money you’re willing to spend
____

[quote]
____
Not all of the public AMIs (Amazon Machine Images) used to create EC2s are vetted by AWS, and there is not an easy way to identify the trust-worthiness of the source account ID that an AMI comes from. There have been issues27 in the past of public AMIs with malware in them. You should identify what AMIs you want to be allowed to run in your environment. You should also document guidelines around the instance types to be used and the OS’s, so you don’t end up with a a dozen flavors of Linux running in your accounts without good reason.
____

== link:https://arxiv.org/pdf/1902.00546v1.pdf[Separating Use and Reuse to Improve Both]

[quote]
____
In Java, C++, Scala and C#, subclassing implies subtyping. A Java subclass declaration, such as `class A extends B {}` does two things at the same time: it inherits code from B; and it creates a subtype of B.
Therefore a subclass must always be a subtype of the extended class. Such design choice where subclassing implies subtyping is not universally accepted.
Historically, there has been a lot of focus on separating subtyping from subclassing. This separation is claimed to be good for code-reuse, design and reasoning. There are at least two distinct situations where the separation of subtyping and subclassing is helpful.

Allowing inheritance/reuse even when subtyping is impossible: Situations where inheritance is desirable are prevented by the enforced subtyping relation. A well-known example are the so-called binary methods. For example, consider a class `Point` with a method `Point sum(Point o){return new Point(x+o.x,y+o.y);}`. Can we reuse the `Point` code so that `ColorPoint.sum` would take and return a `ColorPoint`? In Java/C# declaring class `ColorPoint extends Point{…}` would result in sum still taking a `Point` and returning a `Point`. Moreover, manually redeclaring a `ColorPoint sum(ColorPoint that)` would just induce overloading, not overriding. In this case we would like to have inheritance, but we cannot have (sound) subtyping.

Preventing unintended subtyping: For certain classes we would like to inherit code without creating a subtype even if, from the typing point of view, subtyping is still sound.
A typical example is `Sets` and `Bags`.
Bag implementations can often inherit from Set implementations, and the interfaces of the two collection types are similar and type compatible.
However, from the logical point-of-view a Bag is _not a subtype_ of a Set.

Structural typing may deal with the first situation, but not the second.
Since structural subtyping accounts for the types of the methods only, a Bag would be a subtype of a Set if the two interfaces are type compatible.
For dealing with the second situation, nominal subtyping is preferable: an explicit subtyping relation must be signalled by the programmer. Thus if subtyping is not desired, the programmer can simply not declare a subtyping relationship.

While there is no problem in subtyping without subclassing, in most nominal OO languages subclassing fundamentally implies subtyping. This is because of what we call the this-leaking problem, illustrated by the following (Java) code, where method `A.ma` passes `this` as `A` to `Utils.m`. This code is correct, and there is no subtyping/subclassing.

[source,java]
----
class A{ int ma(){ return Utils.m(this); } }
class Utils{ static int m(A a){…} }
----

Now, lets add a class B:

[source,java]
----
class B extends A{ int mb(){return this.ma();} }
----

We can see an invocation of `A.ma` inside `B.mb`, where the self-reference `this` is of type `B`.
The execution will eventually call `Utils.m` with an instance of `B`. However, _this can be correct only if `B` is a subtype of ``A``.

Suppose Java code-reuse (the `extends` keyword) did not introduce subtyping: then an invocation of `B.mb` would result in a run-time type error.
The problem is that the self-reference `this` in class `B` has type `B`.
Thus, when this is passed as an argument to the method `Utils.m` (as a result of the invocation of `B.mb`), it will have a type that is incompatible with the expected argument of type `A`.
Therefore, every OO language with the minimal features exposed in the example (using `this`, `extends` and method calls) is forced to accept that subclassing implies subtyping.

What the _this-leaking_ problem shows is that adopting a more flexible nominally typed OO model where subclassing does not imply subtyping is not trivial: a more substantial change in the language design is necessary.
In essence we believe that in languages like Java, classes do too many things at once.
In particular they act both as units of use and reuse: classes can be used as types and can be instantiated; classes can also be subclassed to provide reuse of code.
____

== link:https://increment.com/programming-languages/crash-course-in-compilers/[A crash course in compilers]

[quote]
____
I love languages because, of everything I’ve encountered in computing, languages are by far the weirdest. They combine the brain-bending rigor of abstract math, the crushing pressures of capitalistic industry, and the irrational anxiety of a high school prom. The decision to adopt or avoid a language is always a mix of their perceived formal power (“Does this language even have this particular feature?”), employability (“Will this language get me a job?”), and popularity (“Does anyone important use this language anymore?”). I can’t think of another engineering tool that demands similar quasi-religious devotion from its users. Programming languages ask us to reshape our minds, and that makes them deeply personal and subjective.
____
