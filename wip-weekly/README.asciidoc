= Links - Soon
Julien Kirch
v1.0, 2022-01-01
:article_lang: en
:figure-caption!:
:article_description: 

== link:https://gankra.github.io/blah/tower-of-weakenings/[The tower of weakenings: memory models for everyone]

[quote]
____
Just to have it upfront, I will start with what The Tower Of Weakenings _is_, and then go back to the motivation and ideas behind it. The Tower Of Weakenings is simply the idea that having One True Memory Model is a frustrating and futile endeavour that leaves no one satisfied. Instead, we should have a _tower_ of Memory Models, with the ones at the top being "`what users should think about and try to write their code against`". As you descend the tower, the memory models become increasingly complex or vague but _critically_ always more permissive than the ones above it. At the bottom of the tower is "`whatever the compiler actually does`" (and arguably "`whatever the hardware actually does`" in the basement, if you care about that).

Here is a sketch of what the tower looks like under my proposal:

. The "`Clean`" Memory Model: a painfully strict and simple model that you can teach and check.
. The "`Real`" Memory Model: similar to the "`Clean`" one, but messier to allow for Useful Crimes.
. The Compiler's Semantics: whatever random primitives compilers expose, and optimizations they do.

In some sense the bottom of the tower is the one that "`matters`" because that's the thing that (mis)compiles your code, but it's also a shifting target, and link:https://gankra.github.io/blah/initialize-me-maybe/[trying to expose its semantics leads to sadness]. Unfortunately, this is also basically true of "`real`" memory models. link:http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2676.pdf[We're still trying to figure out what on earth C's memory model is], and every language infamously defers to "`the C11 memory model`" on hard questions. So as an educator, I eventually have to bottom out on sending you a shrug-emoji if you keep asking for what the real rules are. No one really knows!
____

[quote]
____
Ok yes get your jokes out about solving all problems with another layer of abstraction, but this is _painfully_ needed. And really, what I'm doing here isn't _adding_ a layer but cleaving a bloated and messy layer into two much more manageable parts. No offense to all the people doing great work on memory models, but as far as I'm concerned they've been given an impossible task. There are simply too many competing concerns and stakeholders to produce a _truly_ satisfying design for all of them. Here are some of the many stakeholders:

* Millions of lines of ancient code that are doing whatever because we can't explain the rules
* Random programmers who barely read the docs and are just doing The Idiomatic Thing
* Hardcore performance junkies who insist the fucked up thing they made should be legal
* Hardcore safety junkies who insist they should be able to validate the correctness of their code
* Compiler developers who want to know what optimizations they can or can't do
* Library developers who want to know what interfaces/idioms to design around
* Tooling developers who want to build sanitizers that reliably detect UB when it happens
* Teachers who want to help everyone else understand the PhD thesis on their desk.
* Memory model people who just want this all to be coherent and formalized and validated

And all of these people are working _together_ so they all agree that whatever the other person claims they need to do their job should definitely be allowed, because they want to all mutually benefit. And definitely make sure not to break all that code or even make it run slower! kthxbai!
____

[quote]
____
Critically, the fact this lie is part of The Tower Of Weakenings means that if you follow its rules, then whatever the "`real`" model is _doesn't matter anymore_. We will absolutely guarantee that your code works, because you followed the really strict and simple rules that _everyone_ can agree _obviously_ have to work. Just as you're not supposed to worry about the compiler backend you're using, you shouldn't have to worry about the fiddly details of what the current working memory model is.
____


== link:https://nilsnh.no/2022/04/09/innovating-beyond-libraries-and-frameworks/[Innovating beyond libraries and frameworks]

[quote]
____
I have been a big fan of the link:https://www.brandons.me/blog/libraries-not-frameworks[write libraries, not frameworks] argument for a while now. Lately, I’ve come to ponder that there might be a fruitful expansion to this argument, that we should start to value principles over patterns, patterns over libraries, and libraries over frameworks.

Let’s clarify some terminology:

* _Framework_: This is (usually) someone else’s code that calls your code. In order for this to work your code will need to conform to constraints set down by the framework. These constraints are often firm boundaries that’s hard to code around. On the flipside by coding within the framework’s conventions and constraints you tend to get a lot of useful functionality out of the box making coding quicker.
* _Library_: This is (usually) someone else’s code that _you call_ from your code. A library tends to be some code that imposes fewer constraints on your code as compared to frameworks. By using one or more libraries you’re able to reuse someone else’s code to solve your problems. Libraries are easier to combine and interchange, while putting frameworks on top of frameworks can lead to a bad time.
* _Pattern_: This is a descriptive, reusable _approach_ to writing your code (see: link:https://en.wikipedia.org/wiki/Software_design_pattern[software design pattern]). Patterns range in their vaguenes, applicability and prescriptiveness. Examples of programming patterns include link:https://www.itamarweiss.com/personal/2018/02/28/return-early-pattern.html[early-return pattern], link:https://en.wikipedia.org/wiki/Builder_pattern[builder-pattern], link:https://en.wikipedia.org/wiki/Actor_model[actor model], link:https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller[model-view-controller], link:https://jeffreypalermo.com/2008/07/the-onion-architecture-part-1/[onion architecture], link:https://en.wikipedia.org/wiki/Microservices[microservices], link:https://m.signalvnoise.com/the-majestic-monolith/[majestic monolith], link:https://en.wikipedia.org/wiki/Monorepo[monorepos], and link:https://en.wikipedia.org/wiki/React_(JavaScript_library)#Unidirectional_data_flow[flux architecture]. These are just some patterns that I can think off from the top of my head, but there are many books that cover programming patterns.
* _Principle_: This is some general guidance or philosophy expressed as rules (like a rule of thumb) that helps you write good code. Although programming is a very young field — for instance compare this to the field of carpentry who have been building houses for thousands of years — developers have managed to distill some useful principles to aid themselves in their work. Examples of principles include link:https://simple.wikipedia.org/wiki/SOLID_(object-oriented_design)[SOLID principles], link:https://en.wikipedia.org/wiki/Don%27t_repeat_yourself[Don’t repeat yourself (DRY)], link:https://en.wikipedia.org/wiki/Don%27t_repeat_yourself[You Aren’t Gonna Need It (YAGNI)], link:https://agilemanifesto.org/[Agile manifesto], link:https://en.wikipedia.org/wiki/Law_of_Demeter[Law of Demeter], link:https://www.hyrumslaw.com/[Hyrum’s law]. There are many more to be found out there, and as I write this I just discovered link:http://principles-wiki.net[this site that collects programming principles], nice!
____

== link:https://logicmag.io/clouds/very-like-a-whale/[Very like a whale]

[quote]
____
Like previous developments in the computing industry, Agile combined counterculture and cyberculture; it was ostensibly rebellious, but committed rebels to sprinting toward corporate goals.
____

== link:https://logicmag.io/clouds/agile-and-the-long-crisis-of-software/[Agile and the long crisis of software]

[quote]
____
Anti-management, maybe, but not anti-corporate, not really. It’s tempting to see the archetypal Agile developer as a revival of the long-haired countercultural weirdo who lurked around the punch card machines of the late 1960s. But the two personas differ in important respects. The eccentrics of computing’s early years wanted to program for the sheer thrill of putting this new technology to work. The coder of Agile’s imagination is committed, above all, to _the project_. He hates administrative intrusion because it gets in the way of his greatest aspiration, which is to do his job at the highest level of professional performance. Like the developers in Aaron Sorkin’s _The Social Network_, he wants most of all to be in "`the zone`": headphones on, distractions eliminated, in a state of pure communion with his labor.
____

== link:https://ferd.ca/errors-are-constructed-not-discovered.html[Errors are constructed, not discovered]

[quote]
____
link:https://en.wikipedia.org/wiki/Hindsight_bias[Hindsight bias] is
something somewhat similar to
link:https://en.wikipedia.org/wiki/Outcome_bias[outcome bias], which
essentially says that because we know there was a failure, every
decision we look at that has taken place before the incident will seem
to us like it should obviously have appeared as risky and wrong. That's
because we know the result, it affects our judgment. But when people
were going down that path and deciding what to do, they were trying to
do a good job; they were making the best calls they could to the extent
of their abilities and the information available at the time.

We can't really avoid hindsight bias, but we can be aware of it. One tip there is to look at what was available at the time, and consider the signals that were available to people. If they made a decision that looks weird, then look for what made it look better than the alternatives back then.
____

[quote]
____
Another one also came from a previous job where an engineer kept
accidentally deleting production databases and triggering a whole
disaster recovery response. They were initially trying to delete a
staging database that was dynamically generated for test cases, but kept
fat-fingering the removal of production instances in the AWS console.
Other engineers were getting mad and felt that person was being
incompetent, and were planning to remove all of their AWS console
permissions because there also existed an admin tool that did the same
thing safely by segmenting environments.

I ended up asking the engineer if there was anything that made them
choose the AWS console more than the admin tool given the difference in
safety, and they said, quite simply, that the AWS console has an
autocomplete and they never remembered the exact table name, so it was
just much faster to delete that table often there than the admin. This
was an interesting one because instead of blaming the engineer for being
incompetent, it opened the door to questioning the gap in tooling rather
than adding more blockers and procedures.
____

[quote]
____
I reached out to the engineers in question and asked about what made
them feel like they had enough tests. I said that we often write tests
up until the point we feel they're not adding much anymore, and that I
was wondering what they were looking at, what made them feel like they
had reached the points where they had enough tests. They just told me
directly that they knew they didn't have enough tests. In fact, they
knew that the code was buggy. But they felt in general that it was safer
to be on-time with a broken project than late with a working one. They
were afraid that being late would put them in trouble and have someone
yell at them for not doing a good job.

And so that revealed a much larger pattern within the organization and
its culture. When I went up to upper management, they absolutely
believed that engineers were empowered and should feel safe pressing a
big red button that stopped feature work if they thought their code
wasn't ready. The engineers on that team felt that while this is what
they were being told, in practice they'd still get in trouble.

There's no amount of test training that would fix this sort of issue.
The engineers knew they didn't have enough tests and they were making
that tradeoff willingly.
____

== link:https://sandimetz.com/blog/2016/1/20/the-wrong-abstraction[The wrong abstraction]

[quote]
____
I've seen problems where folks were trying valiantly to move forward
with the wrong abstraction, but having very little success. Adding new
features was incredibly hard, and each success further complicated the
code, which made adding the next feature even harder. When they altered
their point of view from "`I must preserve our investment in this code`"
to "`This code made sense for a while, but perhaps we've learned all we
can from it`", and gave themselves permission to re-think their
abstractions in light of current requirements, everything got easier.
Once they inlined the code, the path forward became obvious, and adding
new features become faster and easier.

The moral of this story? Don't get trapped by the sunk cost fallacy. If
you find yourself passing parameters and adding conditional paths
through shared code, the abstraction is incorrect. It may have been
right to begin with, but that day has passed. Once an abstraction is
proved wrong the best strategy is to re-introduce duplication and let it
show you what's right. Although it occasionally makes sense to
accumulate a few conditionals to gain insight into what's going on,
you'll suffer less pain if you abandon the wrong abstraction sooner
rather than later.

When the abstraction is wrong, the fastest way forward is back. This is
not retreat, it's advance in a better direction. Do it. You'll improve
your own life, and the lives of all who follow.
____
