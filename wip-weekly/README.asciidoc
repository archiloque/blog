= Links - Soon
Julien Kirch
v1.0, 2022-01-01
:article_lang: en
:figure-caption!:
:article_description: 

== link:https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3979164[Top ten behavioral biases in project management: an overview]

[quote]
____
When Kahneman and I compared notes again, we agreed the balanced position regarding real-world decision-making is that both cognitive and political bias influence outcomes. Sometimes one dominates, sometimes the other, depending on what the stakes are and the degree of political-organizational pressures on individuals. If the stakes are low and political-organizational pressures absent, which is typical for lab experiments in behavioral science, then cognitive bias will dominate and such bias will be what you find. But if the stakes and pressures are high -- for instance, when deciding whether to spend billions of dollars on a new subway line in Manhattan -- political bias and strategic misrepresentation are likely to dominate and will be what you uncover, together with cognitive bias, which is hardwired and therefore present in most, if not all, situations.

Imagine a scale for measuring political-organizational pressures, from weak to strong. At the lower end of the scale, one would expect optimism bias to have more explanatory power of outcomes relative to strategic misrepresentation. But with more political-organizational pressures, outcomes would increasingly be explained in terms of strategic misrepresentation. Optimism bias would not be absent when political-organizational pressures increase, but optimism bias would be supplemented and reinforced by bias caused by strategic misrepresentation. Finally, at the upper end of the scale, with strong political-organizational pressures -- e.g., the situation where a CEO or minister _must_ have a certain project -- one would expect strategic misrepresentation to have more explanatory power relative to optimism bias, again without optimism bias being absent. Big projects, whether in business or government, are typically at the upper end of the scale, with high political-organizational pressures and strategic misrepresentation. The typical project in the typical organization is somewhere in the middle of the scale, exposed to a mix of strategic misrepresentation and optimism bias, where it is not always clear which one is stronger.
____


[quote]
____
Strategic misrepresentation is the tendency to deliberately and systematically distort or misstate information for strategic purposes. This bias is sometimes also called political bias, strategic bias, power bias, or the Machiavelli factor. The bias is a rationalization where the ends justify the means. The strategy (e.g., achieve funding) dictates the bias (e.g., make projects look good on paper). Strategic misrepresentation can be traced to agency problems and political-organizational pressures, for instance competition for scarce funds or jockeying for position. Strategic misrepresentation is deliberate deception, and as such it is lying, per definition.
____

[quote]
____

Finally, recent research has found that not only do political and cognitive biases compound each other in the manner described above. Experimental psychologists have shown that political bias directly amplifies cognitive bias in the sense that people who are powerful are affected more strongly by various cognitive biases -- e.g., availability bias and recency bias -- than people who are not. A heightened sense of power also increases individuals' optimism in viewing risks and their propensity to engage in risky behavior. This is because people in power tend to disregard the rigors of deliberate rationality, which are too slow and cumbersome for their purposes. They prefer -- consciously or not -- subjective experience and intuitive judgment as the basis for their decisions, as documented by Flyvbjerg, who found that people in power will deliberately exclude experts from meetings when much is at stake, in order to avoid clashes in high-level negotiations between power's intuitive decisions and experts' deliberative rationality.
____

[quote]
____
Above we saw that strategic project planners and managers sometimes underestimate cost and overestimate benefit to achieve approval for their projects. Optimistic planners and managers also do this, albeit non-intentionally. The result is the same, however, namely cost overruns and benefit shortfalls. Thus optimism bias and strategic misrepresentation reinforce each other, when both are present in a project. An interviewee in our research described this strategy as "`showing the project at its best`". It results in an inverted Darwinism, i.e., "`survival of the unfittest`". It is not the best projects that get implemented like this, but the projects that look best on paper. And the projects that look best on paper are the projects with the largest cost underestimates and benefit overestimates, other things being equal. But the larger the cost underestimate on paper, the greater the cost overrun in reality. And the larger the overestimate of benefits, the greater the benefit shortfall. Therefore, the projects that have been made to look best on paper become the worst, or unfittest, projects in reality.
____

[quote]
____
Uniqueness bias tends to impede managers’ learning, because they think they have little to learn from other projects as their own project is unique. Uniqueness bias may also feed overconfidence bias and optimism bias, because planners subject to uniqueness bias tend to underestimate risks. This interpretation is supported by research on IT project management reported in Flyvbjerg and Budzier (2011), Budzier and Flyvbjerg (2013), and Budzier (2014). The research found that managers who see their projects as unique perform significantly worse than other managers. If you are a project leader and you overhear team members speak of your project as unique, you therefore need to react.
____

[quote]
____
In the thrall of overconfidence bias, project planners and decision makers underestimate risk by overrating their level of knowledge and ignoring or underrating the role of chance events in deciding the fate of projects. Hiring experts will generally not help, because experts are just as susceptible to overconfidence bias as laypeople and therefore tend to underestimate risk, too. There is even evidence that the experts who are most in demand are the most overconfident. I.e., people are attracted to, and willing to pay for, confidence, more than expertise. Risk underestimation feeds the Iron Law of project management and is the most common cause of project downfall. Good project leaders must know how to avoid this.
____

== link:https://raw.githubusercontent.com/jdjakub/papers/master/prog-2022/prog22-master.pdf[Technical dimensions of programming systems]

[quote]
____
Both Lisp and Smalltalk worked, to some extent, as operating systems. The user started their machine directly in the Lisp or Smalltalk environment and was able to do everything they needed from within the system. This explains why it is worth considering (especially programmer-oriented) operating systems as programming systems too. A prime example of this is UNIX, a 1970s operating system for time-sharing computers.
____

[quote]
____
In using a system, one first has some idea and attempts to make it exist in the software; the gap between the user’s goal and the means to execute the goal is known as the _gulf of execution_. Then, one compares the result actually achieved to the original goal in mind; this crosses the _gulf of evaluation_. These two activities comprise the _feedback loop_ through which a user gradually realises their desires in the imagination, or refines those desires to find out "`what they actually want`".

A system must contain at least one such feedback loop, but may contain several at different levels or specialized to certain domains. For each of them, we can separate the gulf of execution and evaluation as independent legs of the journey, with possibly different manners and speeds of crossing them.
____

[quote]
____
Programmers often think about design details and calculations on a whiteboard or notebook, even before writing code. This _supplementary medium_ has its own feedback loop, even though this is often not automatic.
____

[quote]
____
Composability without convenience is a set of atoms or gears; theoretically, anything one wants could be built out of them, but one must do that work. This situation has been criticized as the _Lisp Curse_.

Composability with convenience is a set of convenient specific tools along with enough components to construct new ones. The specific tools themselves could be transparently composed of these building blocks, but this is not essential. They save users the time and effort it would take to "`roll their own`" solutions to common tasks.

For example, let us turn to a convenience factor of UNIX shell commands, having already discussed their composability above. Observe that it would be possible, in principle, to pass all information to a program via standard input. Yet in actual practice, for convenience, there is a standard interface of _command-line arguments_ instead, separate from anything the program takes through standard input. Most programming systems similarly exhibit both composability and convenience, providing templates, standard libraries, or otherwise pre-packaged solutions, which can nevertheless be used programmatially as part of larger operations.
____
